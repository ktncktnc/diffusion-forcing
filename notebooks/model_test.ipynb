{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s224075134/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from omegaconf import DictConfig\n",
    "from datasets.video.dmlab_video_dataset import DmlabVideoDataset\n",
    "from algorithms.rnn_diffusion_correction.models.vdt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Creating VDT-S/1 model...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_frames = 3\n",
    "input_size = 2\n",
    "in_channels = 1\n",
    "hidden_size=4\n",
    "model_type = 'VDT-S/1'  # Use smaller model for testing\n",
    "\n",
    "# Choose device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model\n",
    "print(f\"Creating {model_type} model...\")\n",
    "model = VDT(\n",
    "    depth=1,\n",
    "    num_heads=1,\n",
    "    hidden_size=hidden_size,\n",
    "    patch_size=1,\n",
    "    input_size=input_size,\n",
    "    in_channels=in_channels,\n",
    "    num_frames=40,\n",
    "    is_causal_crossattn=False\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "_x = torch.randn(batch_size, num_frames, in_channels, input_size, input_size, device=device)\n",
    "_z = torch.randn(batch_size, num_frames, hidden_size, device=device)\n",
    "t = torch.randint(10,100, (batch_size,), device=device).long()  # Timestep tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[  3.7307,   3.3296],\n",
       "           [  3.4312,   3.7017]]],\n",
       "\n",
       "\n",
       "         [[[ 99.6866, 100.6962],\n",
       "           [ 99.7997, 100.8094]]],\n",
       "\n",
       "\n",
       "         [[[  2.4568,   0.1759],\n",
       "           [  3.0913,   2.9595]]]]], device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = _x.clone()\n",
    "z = _z.clone()\n",
    "x[:,1,...]=100\n",
    "# z[:, 2,...]=210\n",
    "\n",
    "model(x, z, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (853863817.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    grad_fn=<ViewBackward0>)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tensor([[[[[3.7307, 3.3296],\n",
    "           [3.4312, 3.7017]]],\n",
    "\n",
    "\n",
    "         [[[1.4641, 1.5118],\n",
    "           [3.3132, 1.4595]]],\n",
    "\n",
    "\n",
    "         [[[2.4053, 0.1639],\n",
    "           [3.0958, 3.0188]]]]], device='cuda:0', grad_fn=<ViewBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1814243405.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    x tensor([[[[ 0.0244, -0.4303, -1.4696, -0.7754],\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tensor([[[[[ 0.1514,  1.5234],\n",
    "           [ 0.9282,  1.1893]]],\n",
    "\n",
    "\n",
    "         [[[-0.2945, -0.3422],\n",
    "           [ 0.6772, -0.0202]]],\n",
    "\n",
    "\n",
    "         [[[ 1.0792,  0.6043],\n",
    "           [-0.2495,  0.7764]]]]], device='cuda:0', grad_fn=<ViewBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_mask_for_cross_attention(3, 2, 'cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "df",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
